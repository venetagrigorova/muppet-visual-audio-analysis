{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5737a30d",
   "metadata": {},
   "source": [
    "# Final Project Summary: Multi-Modal Muppet Character Classification\n",
    "\n",
    "We processed video frames and aligned audio tracks to create a multi-modal dataset. We compared the performance of three classifiers (MLP, SVM, Random Forest) across three experimental setups: **Visual-Only**, **Audio-Only**, and **Combined**.\n",
    "\n",
    "**Key Findings:**\n",
    "1.  **Visual Dominance:** Visual features vastly outperform audio features in isolation.\n",
    "2.  **Modality Imbalance:** Combining features naively led to the model ignoring audio data entirely (99.9% visual importance).\n",
    "3.  **Best Performance:** The MLP classifier on Combined features achieved the highest F1-Score ($\\approx 0.50$), but significant confusion remains between visually similar characters.\n",
    "\n",
    "![](img/f1-combined.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb201c4",
   "metadata": {},
   "source": [
    "## 1. Modality Performance Analysis (ROC Curves)\n",
    "\n",
    "We extracted the ROC curves from our three experimental notebooks to visualize the trade-off between True Positive Rate and False Positive Rate.\n",
    "\n",
    "### Visual vs. Audio Baseline\n",
    "| **Visual ROC** (from NB 1) | **Audio ROC** (from NB 2) |\n",
    "|:---:|:---:|\n",
    "| ![Visual ROC](img/video-roc.png) | ![Audio ROC](img/audio-roc.png) |\n",
    "| *Visual features* | *Audio features* |\n",
    "\n",
    "**Insight:** The visual model is the primary driver of performance. The audio model suffers from class imbalance, predicting the majority class (\"OtherPigs\") frequently, which collapses the AUC for distinct characters like Rowlf.\n",
    "\n",
    "![Combined](img/combined-roc.png)\n",
    "*Combined Features*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1326eea9",
   "metadata": {},
   "source": [
    "## 2. The Modality Imbalance Problem\n",
    "\n",
    "![Feature Importance](img/feature-importance.png)\n",
    "\n",
    "### Critical Observation\n",
    "* **99.9% Visual Importance:** The model effectively ignored the audio data.\n",
    "* **The Cause:** We concatenated a massive visual vector (~8,200 dimensions from HOG) with a tiny audio vector (41 dimensions).\n",
    "* **The Result:** The tree classifiers statistically favored visual splits, treating audio as noise. This confirms that **dimensionality reduction** (PCA) is probably required before fusion to balance the modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864ae7d",
   "metadata": {},
   "source": [
    "## 3. Critical Reflection and Future Improvements\n",
    "\n",
    "Based on our error analysis (Confusion Matrices) and feature importance ranking, we think the following things might improve the performance.\n",
    "\n",
    "### 1. Fix the \"Chef vs. Pig\" Confusion (Visual)\n",
    "* **Problem:** Our visual model (MLP) confused the *Swedish Chef* with *Miss Piggy* ~2,000 times.\n",
    "* **Root Cause:** We converted frames to **Grayscale** for HOG/LBP extraction. Since both characters share similar round shapes and \"bright\" skin tones, they became indistinguishable in grayscale.\n",
    "* **Proposed Fix:** Add an **RGB Color Histogram** feature. The \"Pink\" of the pig vs. the \"White/Orange\" of the chef would likely resolve this confusion immediately.\n",
    "\n",
    "### 2. Solve Modality Imbalance (Fusion)\n",
    "* **Problem:** The 99.9% vs 0.1% importance split caused the Audio modality to be wasted.\n",
    "* **Proposed Fix:** Apply **PCA** to the Visual features *before* concatenation. Reducing the visual vector from 8,200 to ~50 components (matching the Audio size) would force the classifier to weigh both modalities equally.\n",
    "\n",
    "### 3. Address Audio Noise (Temporal)\n",
    "* **Problem:** Audio classification on single video frames (1/25th of a second) is unstable.\n",
    "* **Proposed Fix:** Instead of classifying individual frames, we should aggregate features over a **1-second window** (e.g., rolling mean of 25 frames). This would smooth out momentary silence or noise and capture the temporal context of the voice (phonemes/words)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
